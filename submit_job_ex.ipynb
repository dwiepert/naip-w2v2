{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertex AI job submit\n",
    "\n",
    "This is an extended tutorial from [aif_training_job_tutorial](https://github.com/MayoNeurologyAI/aif_training_job_tutorial) with specifics for running a model folder with multiple dependencies and additional requirements. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Docker\n",
    "Make sure Docker is installed on your machine. You can download and install Docker from the official Docker website (https://www.docker.com/).\n",
    "\n",
    "Once it is installed, you only need to start the application to gain access to Docker. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Authorize access to google cloud and docker images\n",
    "<font color='red'>Please execute the commands in the cell below consecutively on your terminal or command prompt.</font>\n",
    "\n",
    "Also make sure that Mayo VPN is active at the time of running these commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# authenticate google cloud\n",
    "$ gcloud auth login\n",
    "\n",
    "# set project to fdgpet project\n",
    "$ gcloud config set project ml-mps-aif-afdgpet01-p-6827\n",
    "\n",
    "# Authenticating to Access Docker Images from the Google Container Registry in AIF\n",
    "$ gcloud auth configure-docker us-central1-docker.pkg.dev\n",
    "$ gcloud auth configure-docker us.gcr.io"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a DockerFile\n",
    "\n",
    "Create a Dockerfile as in `./Dockerfile`. The `Dockerfile` extends the AIF image `us.gcr.io/ml-mps-aif-afdgpet01-p-6827/speech:latest`. It can also install additional requirements from pip and can do conda installs if necessary.\n",
    "\n",
    "The version of the Dockerfile used in this repository ([mayo-w2v2](https://github.com/dwiepert/mayo-w2v2)) has some specific commands to consider.\n",
    "Because of the structure, the src folder must be copied fully, set as the working dir, and run so that relative imports function properly. \n",
    "\n",
    "   ##### AIF image `us.gcr.io/ml-mps-aif-afdgpet01-p-6827/speech:latest`:\n",
    "        \n",
    "      This is pytorch image that includes all packages listed in `base_requirements.txt` + dependencies from the base container (`gcr.io/deeplearning-platform-release/pytorch-gpu.1-13.py310`)\n",
    "      Note that the base image also includes conda install of ffmpeg.\n",
    "\n",
    "      You can also see [Prebuilt container image dependencies](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers#pytorch) and\n",
    "      [Pre-installed software in containers](https://cloud.google.com/deep-learning-containers/docs/overview#pre-installed_software) for the dependencies from the base container.\n",
    "\n",
    "   \n",
    "   ##### Script `run.py`:\n",
    "\n",
    "      This can be altered to be whatever script is running your model. For our purposes, it is always `run.py`. There is also a [test.py](https://github.com/dwiepert/mayo-w2v2/src/test.py) script in src code for mayo-w2v2 that can be used if you want to test that all relative imports are functioning properly. \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "`Dockerfile`\n",
    "----------------------------------\n",
    "# use a Google maintained base image hosted in \n",
    "# Google's container registry\n",
    "FROM us.gcr.io/ml-mps-aif-afdgpet01-p-6827/speech:latest\n",
    "\n",
    "## IF YOU HAVE ADDITIONAL PACKAGE DEPENDENCIES TO INSTALL WITH PIP, UNCOMMENT THE FOLLOWING CODE:\n",
    "# ARG AIF_PIP_INDEX\n",
    "# RUN pip install -i $AIF_PIP_INDEX --upgrade pip\n",
    "# COPY requirements.txt requirements.txt\n",
    "# RUN pip install -r requirements.txt\n",
    "\n",
    "## IF YOU HAVE ANY ADDITIONAL PACKAGE DEPENDENCIES TO INSTALL WITH CONDA, UNCOMMENT THE FOLLOWING CODE:\n",
    "# RUN conda install -y package_name=version\n",
    "\n",
    "## COPY PYTHON SCRIPTS\n",
    "#1. make src directory\n",
    "RUN mkdir /src      \n",
    "\n",
    "#2. set src as working dir\n",
    "WORKDIR /src\n",
    "\n",
    "#3. copy all files from src\n",
    "COPY ./src /src\n",
    "\n",
    "#4. set python path\n",
    "RUN export PYTHONPATH=/src/\n",
    "\n",
    "# RUN dir #uncomment if wanting a printed list of items in the directory\n",
    "\n",
    "## IF YOU WANT TO EXECUTE CODE IMMEDIATELY UPON RUNNING CONTAINER, UNCOMMENT THE FOLLOWING CODE:\n",
    "# ENTRYPOINT [\"python\", \"run.py\"]\n",
    "#if commented, you can execute a bash and run whatever scripts are available in the container as if you are in a terminal with those files."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "`base_requirements.txt` (for base AIF image)\n",
    "----------------------------------\n",
    "dask==2023.5.0\n",
    "pyarrow==12.0.0\n",
    "pytest==7.3.1\n",
    "tqdm==4.65.0\n",
    "matplotlib==3.7.1\n",
    "\n",
    "#audio\n",
    "ffmpeg==1.4\n",
    "librosa==0.10.0.post2\n",
    "\n",
    "#data augmentation\n",
    "albumentations==1.3.0\n",
    "\n",
    "#torch-based \n",
    "torchvision==0.14.0\n",
    "torchaudio==0.13.1\n",
    "\n",
    "#model building\n",
    "transformers==4.28.1\n",
    "timm==0.4.5\n",
    "speechbrain==0.5.14"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Build a docker image locally\n",
    "The following command(s) allows you to build a Docker image locally on your machine based on the specifications defined in the Dockerfile.\n",
    "\n",
    "\n",
    "<font color='green'>Please note the following points regarding the usage of `LOCAL_IMAGE_NAME[:TAG]`</font>:\n",
    "\n",
    "<ul>\n",
    "    <li> You can choose any name and tag for the <LOCAL_IMAGE_NAME[:TAG]> parameter. This is for local reference and helps you identify and manage your Docker images.</li>\n",
    "    <li> If you use an existing local image name and tag, the new Docker image will replace the previous one with the same name and tag. Be cautious when reusing image names and tags to avoid unintentionally overwriting existing images.</li>\n",
    "</ul>\n",
    "\n",
    "<font color='red'> Note: If you are building a local image from AIF, you will need to be connected to the VPN. Also, depending on how large the image is, this initial local build can take a long time (e.g., a 25GB image could take over 2 hours, so plan accordingly).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# `speech_test_script` is the LOCAL_IMAGE_NAME and `latest` is the TAG we specified for this example\n",
    "\n",
    "#can run these in a terminal or command shell\n",
    "\n",
    "#version that works with a Dockerfile in the same directory as the notebook. Must `cd` into the directory with the Dockerfile to run this way. \n",
    "# Buildx version is the same, but explicitly indicates you are using the non-depreciated version of build. \n",
    "!docker build -t speech_test_script:latest .\n",
    "!docker buildx build -t speech_test_script:latest .\n",
    "\n",
    "#could also give a path to the Dockerfile (based on whatever dir you are currently in)\n",
    "!docker buildx build -t speech_test_script:latest -f PATH_TO_DOCKERFILE . "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Run Docker Image Locally\n",
    "This container can be run locally BUT if you are doing a job submission just skip this part of the step and move directly to 3.3. There are two ways you can work with the container. \n",
    "\n",
    "1. If you specified a script to execute upon running the container, you can use \n",
    "\n",
    "```\n",
    "    docker run <LOCAL_IMAGE_NAME[:TAG]> --user-arg1 user-arg1-value --user-arg2 user-arg2-value\n",
    "```\n",
    "\n",
    "The user-args are based on whatever args are defined in your specified script. \n",
    "#### <font color=\"red\"> Please note that in this situtation, the Docker container does not have access to Google Cloud authentication. However, when we submit a training job, we will gain access to Google Cloud resources.</font>\n",
    "\n",
    "2. If you did not specify a script to execute, you can run the docker container and execute into the container to run any of the scripts. This version allows you to have access to Google Cloud authentication locally. \n",
    "\n",
    "```$ docker run -it <LOCAL_IMAGE_NAME[:TAG]>```\n",
    "\n",
    "#### <font color=\"red\"> Note: Run the below command inside a terminal window or command prompt. </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running with entry point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ docker run speech_test_script:latest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running with bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ docker run -it speech_test_script:latest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access Running Docker container\n",
    "\n",
    "Find `container_id` using `docker ps -a` and then access running docker container with \n",
    "```\n",
    "    docker exec -it container_id bash\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! docker ps -a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"red\"> Note: Run the below command inside a new terminal window or command prompt</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# executes the container (don't forget to change the container id)\n",
    "$ docker exec -it a4652310229d bash"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set access within running container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# autheticate the container with your credentials\n",
    "$ gcloud auth login --update-adc\n",
    "\n",
    "# set project id\n",
    "$ gcloud config set project ml-mps-aif-afdgpet01-p-6827"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run a script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# run test.py\n",
    "$ python test.py \n",
    "\n",
    "# exit container after successful execution\n",
    "$ exit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup container locally\n",
    "Stop and remove the container\n",
    "\n",
    "``` $ docker stop container_id```\n",
    "\n",
    "``` $ docker rm container_id ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! docker stop a4652310229d   \n",
    "\n",
    "! docker rm a4652310229d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Tag the Docker image\n",
    "Use the docker tag command to assign a specific tag to your Docker image. This tag helps identify and manage different versions or variations of the image.\n",
    "\n",
    "```\n",
    "docker tag -t <LOCAL_IMAGE_NAME[:TAG]> TARGET_IMAGE[:TAG]\n",
    "```\n",
    "\n",
    "<font color='green'>Please note the following points regarding the usage of `TARGET_IMAGE[:TAG]`</font>:\n",
    "\n",
    "<ul>\n",
    "    <li> It should be of the format <font color=\"green\">us-central1-docker.pkg.dev/[PROJECT-ID]/[DATASET-ID]/[REMOTE-IMAGE-NAME][:TAG]</font></li>\n",
    "    <li> Referring to [REMOTE-IMAGE-NAME][:TAG], it corresponds to the image name you wish to have in AIF. If you utilize an existing AIF image name and tag, the new Docker image will replace the previous one that shares the same name and tag. Exercise caution when reusing image names and tags to prevent unintended overwriting of existing images.</li>\n",
    "    <li> To enchance the organization of images on AIF, use the same `REMOTE-IMAGE-NAME` wherever possible to avoid having too many images, however use distincr TAG names to make sure you do not overwrite someone else's work. <font color=\"red\">Please take caution in this step so you don't accidentally overwrite someone else's Image</font>.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# LOCAL_IMAGE_NAME[:TAG] is the one used in previous step: speech_test_script:latest\n",
    "# TARGET_IMAGE[:TAG] is of the format `us-central1-docker.pkg.dev/[PROJECT-ID]/[DATASET-ID]/[IMAGE-NAME][:TAG]` where,\n",
    "#   PROJECT-ID = ml-mps-aif-afdgpet01-p-6827\n",
    "#   DATASET-ID = phi-main-us-central1-p\n",
    "#   IMAGE-NAME = speech_test_script\n",
    "#   TAG = test-latest\n",
    "\n",
    "!docker tag speech_test_script:latest us-central1-docker.pkg.dev/ml-mps-aif-afdgpet01-p-6827/phi-main-us-central1-p/speech_test_w2v2:m144443-latest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Push the Docker image to AIF\n",
    "<font color=\"red\">Note: when pushing the docker image to AIF, please double check your TARGET-IMAGE-NAME and TAG to make sure it is unique to you.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# docker push us-central1-docker.pkg.dev/[PROJECT-ID]/[DATASET-ID]/[TARGET-IMAGE-NAME][:TAG]\n",
    "!docker push us-central1-docker.pkg.dev/ml-mps-aif-afdgpet01-p-6827/phi-main-us-central1-p/speech_test_w2v2:m144443-latest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can view the published image in `Artifact Registry` on AI Factory\n",
    "\n",
    "https://console.cloud.google.com/artifacts/docker/ml-mps-aif-afdgpet01-p-6827/us-central1/phi-main-us-central1-p?project=ml-mps-aif-afdgpet01-p-6827"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Edit `config.json` \n",
    "\n",
    "Modify `imageUri` & `args` accordingly\n",
    "\n",
    "Note:\n",
    "  <ul>\n",
    "  <li><font color=\"green\"> The args parameter is a list of command line arguments that can be passed to the script. </font></li>\n",
    " \n",
    "  <li><font color=\"green\">The imageUri refers to the Docker image (TARGET_IMAGE[:TAG]) that you pushed to AIF in step 2.3. Please make sure TARGET_IMAGE[:TAG] information in the config.json is the same as before </font></li>\n",
    "  </ul>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"containerSpec\": {\n",
    "    \"imageUri\": us-central1-docker.pkg.dev/[PROJECT-ID]/[DATASET-ID]/[REMOTE-IMAGE-NAME][:TAG],\n",
    "    \"args\": [\n",
    "    \"<generic user arg name 1>\"=\"<user args value>\",\n",
    "    \"<generic user arg name 2>\"=\"<user args value>\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing files as arguments\n",
    "\n",
    "When passing files as arguments, you will need to copy any local files over to the google cloud storage bucket with  ```gsutil cp PATH_TO_FILE gs://bucket-name/PATH_TO_SAVE```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run training job with `config.json`\n",
    "\n",
    "<font color=\"red\">Note: In the comand below, the --display-name can be anything you choose, as it is used for identification purposes. We would suggest including your lanid in the display name to differentiate which job is yours, that way when multiple jobs are running it is easy to differentiate yours from someone else's </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# test_speech_gpu is the display name for this examples\n",
    "\n",
    "!gcloud ai custom-jobs create \\\n",
    "  --region=us-central1 \\\n",
    "  --display-name=speech_test_w2v2 \\\n",
    "  --config=config.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training job status\n",
    "##### Please visit https://console.cloud.google.com/vertex-ai/training/custom-jobs?project=ml-mps-aif-afdgpet01-p-6827 to check the job status\n",
    "\n",
    "##### Also visit google cloud storage path to check if the log file exists"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
